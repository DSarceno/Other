{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos el csv con la data ya limpia y preprocesada\n",
    "imdbesmod = pd.read_csv(r'../data/imdb_espaniol_mod.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aislamos las columnas a utilizar y revisamos los tipos de datos\n",
    "imdbesmodcopy = imdbesmod[['sentiemiento_token', 'review_es_mod']]\n",
    "imdbesmodcopy['sentiemiento_token'] = imdbesmodcopy['sentiemiento_token'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'revolvemos' el dataframe y lo dividimos en test y train\n",
    "imdbesmodcopy = imdbesmodcopy.sample(frac=1)\n",
    "imdbesmodcopy_train = imdbesmodcopy.iloc[2500:]\n",
    "imdbesmodcopy_test = imdbesmodcopy.iloc[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el tokenizador con 10000 palabras como maximo\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(imdbesmodcopy_train['review_es_mod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length: 1870\n"
     ]
    }
   ],
   "source": [
    "# cambiando el texto a secuencias para su posterior 'embedding'\n",
    "X_train = tokenizer.texts_to_sequences(imdbesmodcopy_train['review_es_mod'])\n",
    "X_test = tokenizer.texts_to_sequences(imdbesmodcopy_test['review_es_mod'])\n",
    "\n",
    "# pad sequences\n",
    "maxlen = max([len(x) for x in X_train])\n",
    "\n",
    "print('Max Length:', maxlen)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos las etiquetas en train y test\n",
    "y_train = imdbesmodcopy_train['sentiemiento_token'].values\n",
    "y_test = imdbesmodcopy_test['sentiemiento_token'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validacion y evaluacion\n",
    "validation_split = 0.5\n",
    "validation_size  =int(len(X_test) * validation_split)\n",
    "\n",
    "X_val = X_test[:validation_size]\n",
    "y_val = y_test[:validation_size]\n",
    "\n",
    "X_eval = X_test[validation_size:]\n",
    "y_eval = y_test[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la dimensionalidad del embedding\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo y su arquitectura\n",
    "model = Sequential([\n",
    "    Embedding(max_features, embed_size),\n",
    "    LSTM(60, return_sequences=True),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo compilamos\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n",
      "Epoch 1/30\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2114s\u001b[0m 6s/step - accuracy: 0.7404 - loss: 0.4864 - val_accuracy: 0.8936 - val_loss: 0.2629\n",
      "Epoch 2/30\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2384s\u001b[0m 6s/step - accuracy: 0.9144 - loss: 0.2192 - val_accuracy: 0.8824 - val_loss: 0.3042\n",
      "Epoch 3/30\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2487s\u001b[0m 7s/step - accuracy: 0.9401 - loss: 0.1641 - val_accuracy: 0.8880 - val_loss: 0.2970\n",
      "Epoch 4/30\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2489s\u001b[0m 7s/step - accuracy: 0.9678 - loss: 0.1008 - val_accuracy: 0.8808 - val_loss: 0.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x242e5f28290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenamos el modelo\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "early_stoppping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stoppping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 831ms/step - accuracy: 0.8833 - loss: 0.2904\n",
      "Test loss: 0.30798858404159546 - Test accuracy: 0.8751999735832214\n"
     ]
    }
   ],
   "source": [
    "# vemos el score del modelo\n",
    "score = model.evaluate(X_eval, y_eval, batch_size=batch_size)\n",
    "\n",
    "print(f'Test loss: {score[0]} - Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos el modelo en un archivo .h5 asi como sus pesos y el tokenizer\n",
    "import json\n",
    "import keras\n",
    "\n",
    "## Modelo\n",
    "#model.save(r'../model/csModel.h5')\n",
    "keras.saving.save_model(model, 'my_model.keras')\n",
    "\n",
    "## guardamos los pesos (weights)\n",
    "model.save_weights(r'../model/csModel.weights.h5')\n",
    "\n",
    "## Tokenizador\n",
    "with open(r\"../model/cs_tokenizer.json\", \"w\") as j:\n",
    "    json.dump(tokenizer.to_json(), j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# utilizando earlystopping\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir el modelo con EarlyStopping\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Embedding(max_features, embed_size),\n",
    "        LSTM(60, return_sequences=True),\n",
    "        GlobalMaxPool1D(),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función para probar diferentes combinaciones de hyperparámetros\n",
    "def evaluate_model(X_train, y_train, X_val, y_val, batch_sizes, epochs_list):\n",
    "    results = []\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        for epochs in epochs_list:\n",
    "            # EarlyStopping: Detener entrenamiento si no hay mejoras en 3 épocas\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            \n",
    "            # Construir y entrenar el modelo\n",
    "            model = build_model()\n",
    "            \n",
    "            print(f\"Entrenando modelo con batch_size={batch_size} y epochs={epochs}\")\n",
    "            \n",
    "            # Medir el tiempo de entrenamiento\n",
    "            start_time = time.time()\n",
    "            \n",
    "            history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                                validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            \n",
    "            # Guardar resultados\n",
    "            val_accuracy = history.history['val_accuracy'][-1]\n",
    "            results.append({\n",
    "                'batch_size': batch_size,\n",
    "                'epochs': epochs,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'training_time': training_time\n",
    "            })\n",
    "            \n",
    "            print(f\"Completado: val_accuracy={val_accuracy:.4f}, tiempo={training_time:.2f} segundos\")\n",
    "    \n",
    "    return results\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los tamaños de lote y el número de épocas que quieres probar\n",
    "#batch_sizes = [32, 64, 128]\n",
    "#epochs_list = [10, 30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "#results = evaluate_model(X_train, y_train, X_val, y_val, batch_sizes, epochs_list)\n",
    "\n",
    "#Entrenando modelo con batch_size=32 y epochs=10\n",
    "#AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n",
    "#Completado: val_accuracy=0.8800, tiempo=2996.96 segundos\n",
    "#Entrenando modelo con batch_size=32 y epochs=30\n",
    "#Completado: val_accuracy=0.8848, tiempo=3750.51 segundos\n",
    "#Entrenando modelo con batch_size=32 y epochs=50\n",
    "#Completado: val_accuracy=0.8832, tiempo=3706.10 segundos\n",
    "#Entrenando modelo con batch_size=64 y epochs=10\n",
    "#Completado: val_accuracy=0.8808, tiempo=4486.20 segundos\n",
    "#Entrenando modelo con batch_size=64 y epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 10,\n",
    "        'val_accuracy': 0.8800,\n",
    "        'training_time': 2996.96\n",
    "    },\n",
    "    {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 30,\n",
    "        'val_accuracy': 0.8848,\n",
    "        'training_time': 3750.51\n",
    "    },\n",
    "    {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 50,\n",
    "        'val_accuracy': 0.8832,\n",
    "        'training_time': 3706.10\n",
    "    },\n",
    "    {\n",
    "        'batch_size': 64,\n",
    "        'epochs': 10,\n",
    "        'val_accuracy': 0.8808,\n",
    "        'training_time': 4486.20\n",
    "    },\n",
    "]\n",
    "# Mostrar los resultados\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Opcional: Graficar la relación entre batch_size, epochs y val_accuracy\n",
    "batch_sizes_vals = [result['batch_size'] for result in results]\n",
    "epochs_vals = [result['epochs'] for result in results]\n",
    "val_accuracies = [result['val_accuracy'] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(epochs_vals, batch_sizes_vals, c=val_accuracies, cmap='viridis', s=100)\n",
    "plt.colorbar(label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Batch Size')\n",
    "plt.title('Evaluación de Hyperparámetros (Batch Size vs Epochs vs Val Accuracy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probando el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = [\n",
    "    \"El café en este lugar es increíblemente aromático y el ambiente es perfecto para relajarse. ¡Muy recomendado!\",\n",
    "    \"El servicio fue lento y las porciones pequeñas para el precio. No lo recomendaría.\",\n",
    "    \"El libro tiene una trama cautivadora y personajes memorables. Me mantuvo enganchado de principio a fin.\",\n",
    "    \"La película fue predecible y los efectos especiales parecían anticuados. Me decepcionó.\",\n",
    "    \"Este champú dejó mi cabello suave y brillante, y el aroma es maravilloso. Definitivamente lo volveré a comprar.\",\n",
    "    \"La aplicación se traba constantemente y consume mucha batería. No vale la pena descargarla.\",\n",
    "    \"La chaqueta es súper cómoda y tiene un diseño moderno. Perfecta para el invierno.\",\n",
    "    \"La comida llegó fría y con un sabor mediocre. No volveré a pedir de aquí.\",\n",
    "    \"El curso es muy claro y los ejemplos son prácticos. Aprendí muchísimo en poco tiempo.\",\n",
    "    \"Las instrucciones no eran claras y el producto vino defectuoso. Un desperdicio de dinero.\"\n",
    "]\n",
    "sentimiento = [\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo'\n",
    "]\n",
    "resenias = pd.DataFrame({'review_es': prueba, 'sentimiento': sentimiento})\n",
    "resenias = resenias.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "# APLICADO A COLUMNAS\n",
    "\n",
    "# Función para eliminar etiquetas HTML de una columna\n",
    "def eliminar_etiquetas_html(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'<.*?>', '', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Función para limpiar caracteres especiales de una columna\n",
    "def limpiar_texto(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'[^\\w\\s.,]', '', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# ------------->\n",
    "# correción de funcion para limpiar caracteres especiales\n",
    "def caracteres_especiales(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def espacios_extra(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'\\s+', ' ', x).strip() if isinstance(x, str) else x)\n",
    "    return df\n",
    "# ------------->\n",
    "\n",
    "# Función para eliminar palabras vacías de una columna\n",
    "def remove_stop_words(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    df[col_out] = df[col_in].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def lemmatizador(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    # cargamos el modelo en espaniol\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "    # aplicamos a cada fila de la columna entrada\n",
    "    df[col_out] = df[col_in].apply(\n",
    "        lambda x: ' '.join([token.lemma_ for token in nlp(x)]) if isinstance(x, str) else x\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipe(df : pd.DataFrame, col_in : str, col_out : str) -> pd.DataFrame:\n",
    "    result = (df\n",
    "              .pipe(eliminar_etiquetas_html, col_in, col_out)\n",
    "              .pipe(caracteres_especiales, col_out, col_out)\n",
    "              .pipe(espacios_extra, col_out, col_out)\n",
    "              .pipe(remove_stop_words, col_out, col_out)\n",
    "              .pipe(lemmatizador, col_out, col_out))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenias_treated = preprocessing_pipe(resenias, 'review_es', 'review_es_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1870"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiando el texto a secuencias para su posterior 'embedding'\n",
    "x_review_tests = tokenizer.texts_to_sequences(resenias_treated['review_es_mod'])\n",
    "x_review_tests = sequence.pad_sequences(x_review_tests, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n"
     ]
    }
   ],
   "source": [
    "prediccion = model.predict(x_review_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_clase = prediccion.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion_clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenias_treated['prediccion'] = prediccion_clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenias_treated['prediccion'] = resenias_treated['prediccion'].map({1 : 'positivo', 0 : 'negativo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>review_es_mod</th>\n",
       "      <th>prediccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El café en este lugar es increíblemente aromát...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>café lugar increíblemente aromático ambiente p...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La aplicación se traba constantemente y consum...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>aplicación trar constantemente consumir mucho ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La chaqueta es súper cómoda y tiene un diseño ...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>chaqueta súper cómodo diseño moderno Perfecta ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El servicio fue lento y las porciones pequeñas...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>servicio lento porción pequeño precio recomendar</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este champú dejó mi cabello suave y brillante,...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>champú dejar cabello suave brillante aroma mar...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La comida llegó fría y con un sabor mediocre. ...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>comida llegar fría sabor mediocre volver pedir...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La película fue predecible y los efectos espec...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>película predecible efecto especial parecer an...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El curso es muy claro y los ejemplos son práct...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>curso claro ejemplo práctico Aprendí muchísimo...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El libro tiene una trama cautivadora y persona...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>libro trama cautivadora personaje memorable ma...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Las instrucciones no eran claras y el producto...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>instrucción claro producto venir defectuoso de...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_es sentimiento  \\\n",
       "0  El café en este lugar es increíblemente aromát...    positivo   \n",
       "5  La aplicación se traba constantemente y consum...    negativo   \n",
       "6  La chaqueta es súper cómoda y tiene un diseño ...    positivo   \n",
       "1  El servicio fue lento y las porciones pequeñas...    negativo   \n",
       "4  Este champú dejó mi cabello suave y brillante,...    positivo   \n",
       "7  La comida llegó fría y con un sabor mediocre. ...    negativo   \n",
       "3  La película fue predecible y los efectos espec...    negativo   \n",
       "8  El curso es muy claro y los ejemplos son práct...    positivo   \n",
       "2  El libro tiene una trama cautivadora y persona...    positivo   \n",
       "9  Las instrucciones no eran claras y el producto...    negativo   \n",
       "\n",
       "                                       review_es_mod prediccion  \n",
       "0  café lugar increíblemente aromático ambiente p...   positivo  \n",
       "5  aplicación trar constantemente consumir mucho ...   positivo  \n",
       "6  chaqueta súper cómodo diseño moderno Perfecta ...   positivo  \n",
       "1   servicio lento porción pequeño precio recomendar   negativo  \n",
       "4  champú dejar cabello suave brillante aroma mar...   positivo  \n",
       "7  comida llegar fría sabor mediocre volver pedir...   negativo  \n",
       "3  película predecible efecto especial parecer an...   negativo  \n",
       "8  curso claro ejemplo práctico Aprendí muchísimo...   negativo  \n",
       "2  libro trama cautivadora personaje memorable ma...   positivo  \n",
       "9  instrucción claro producto venir defectuoso de...   negativo  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resenias_treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con un dataset mayor\n",
    "Dataset: ./model/netflix/film_reviews_result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los datos\n",
    "netflix = pd.read_csv(r'./model/netflix/film_reviews_result.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
