{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# librerías para el texto\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "# utilizando Natural Language Toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# utilizando Tensorflow\n",
    "# probando tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_es = pd.read_csv(r'../data/IMDB_spanish.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_en</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>Pensé que esta película hizo un buen trabajo a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>Mala parcela, mal diálogo, mala actuación, dir...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>Soy católica enseñada en escuelas primarias pa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>Voy a tener que estar en desacuerdo con el com...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>Nadie espera que las películas de Star Trek se...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          review_en  \\\n",
       "0               0  One of the other reviewers has mentioned that ...   \n",
       "1               1  A wonderful little production. The filming tec...   \n",
       "2               2  I thought this was a wonderful way to spend ti...   \n",
       "3               3  Basically there's a family where a little boy ...   \n",
       "4               4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "...           ...                                                ...   \n",
       "49995       49995  I thought this movie did a down right good job...   \n",
       "49996       49996  Bad plot, bad dialogue, bad acting, idiotic di...   \n",
       "49997       49997  I am a Catholic taught in parochial elementary...   \n",
       "49998       49998  I'm going to have to disagree with the previou...   \n",
       "49999       49999  No one expects the Star Trek movies to be high...   \n",
       "\n",
       "                                               review_es sentiment sentimiento  \n",
       "0      Uno de los otros críticos ha mencionado que de...  positive    positivo  \n",
       "1      Una pequeña pequeña producción.La técnica de f...  positive    positivo  \n",
       "2      Pensé que esta era una manera maravillosa de p...  positive    positivo  \n",
       "3      Básicamente, hay una familia donde un niño peq...  negative    negativo  \n",
       "4      El \"amor en el tiempo\" de Petter Mattei es una...  positive    positivo  \n",
       "...                                                  ...       ...         ...  \n",
       "49995  Pensé que esta película hizo un buen trabajo a...  positive    positivo  \n",
       "49996  Mala parcela, mal diálogo, mala actuación, dir...  negative    negativo  \n",
       "49997  Soy católica enseñada en escuelas primarias pa...  negative    negativo  \n",
       "49998  Voy a tener que estar en desacuerdo con el com...  negative    negativo  \n",
       "49999  Nadie espera que las películas de Star Trek se...  negative    negativo  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APLICADO A COLUMNAS\n",
    "\n",
    "# Función para eliminar etiquetas HTML de una columna\n",
    "def eliminar_etiquetas_html(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'<.*?>', '', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Función para limpiar caracteres especiales de una columna\n",
    "def limpiar_texto(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'[^\\w\\s.,]', '', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# ------------->\n",
    "# correción de funcion para limpiar caracteres especiales\n",
    "def caracteres_especiales(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def espacios_extra(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    df[col_out] = df[col_in].apply(lambda x: re.sub(r'\\s+', ' ', x).strip() if isinstance(x, str) else x)\n",
    "    return df\n",
    "# ------------->\n",
    "\n",
    "# Función para eliminar palabras vacías de una columna\n",
    "def remove_stop_words(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    df[col_out] = df[col_in].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def lemmatizador(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    # cargamos el modelo en espaniol\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "    # aplicamos a cada fila de la columna entrada\n",
    "    df[col_out] = df[col_in].apply(\n",
    "        lambda x: ' '.join([token.lemma_ for token in nlp(x)]) if isinstance(x, str) else x\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def sentiment_token(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    conditions = [\n",
    "        df[col_in] == 'positivo',\n",
    "        df[col_in] == 'negativo']\n",
    "    labels = [1, 0]\n",
    "    df[col_out] = np.select(conditions, labels, default=np.nan)\n",
    "    return df\n",
    "\n",
    "def rating(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    conditions = [\n",
    "        (df[col_in] >= 0) & (df[col_in] < 4),\n",
    "        (df[col_in] >= 4) & (df[col_in] <= 6),\n",
    "        (df[col_in] > 6) & (df[col_in] <= 10)]\n",
    "    labels = ['Mala', 'Pasable/Normal', 'Buena']\n",
    "    df[col_out] = np.select(conditions, labels, default=np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def rating_token(df : pd.DataFrame, col_in : str | int, col_out : str | int) -> pd.DataFrame:\n",
    "    conditions = [\n",
    "        (df[col_in] >= 0) & (df[col_in] <= 5),\n",
    "        (df[col_in] >= 6) & (df[col_in] <= 10)]\n",
    "    labels = [0, 1]\n",
    "    df[col_out] = np.select(conditions, labels, default=np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def vectorizador(texto : str) -> torch.Tensor:\n",
    "    # se tokeniza la oración para convertirse en una estructura BERT\n",
    "    inputs = tokenizer(texto, return_tensors='pt')\n",
    "\n",
    "    # se desactiva el calculo del gradiente\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # extraemos los embeddings\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def obtener_embeddings(texto : str) -> np.array:\n",
    "    # Mover el modelo a GPU si está disponible\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenización del texto y creacion de tensores\n",
    "    inputs = tokenizer(texto, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generar embeddings con BERT sin cálculo de gradientes\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # tomar el embedding de la ultima capa\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_embedding(texto : str) -> np.array:\n",
    "    # Tokenizacion y creación de tensores\n",
    "    inputs = tokenizer(texto, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad(): # desactivar el calculo de gradientes\n",
    "        outputs = model(**inputs)\n",
    "        # extraer el embedding de [CLS] (índice 0)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbescopy = imdb_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbescopy = (imdbescopy\n",
    "              .pipe(sentiment_token, 'sentimiento', 'sentiemiento_token')\n",
    "              .pipe(eliminar_etiquetas_html, 'review_es', 'review_es_mod')\n",
    "              .pipe(caracteres_especiales, 'review_es_mod', 'review_es_mod')\n",
    "              .pipe(espacios_extra, 'review_es_mod', 'review_es_mod')\n",
    "              .pipe(remove_stop_words, 'review_es_mod', 'review_es_mod')\n",
    "              .pipe(lemmatizador, 'review_es_mod', 'review_es_mod'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbescopy.to_csv(r'../data/imdb_espaniol_mod.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_embedding(review : pd.Series, model : gensim.models.word2vec.Word2Vec): \n",
    "    word_vectors = [model.wv[word] for word in review if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbesmod = pd.read_csv(r'../data/imdb_espaniol_mod.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daalvarado\\AppData\\Local\\Temp\\ipykernel_38532\\2524330471.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imdbesmodcopy['sentiemiento_token'] = imdbesmodcopy['sentiemiento_token'].astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "imdbesmodcopy = imdbesmod[['sentiemiento_token', 'review_es_mod']]\n",
    "imdbesmodcopy['sentiemiento_token'] = imdbesmodcopy['sentiemiento_token'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbesmodcopy = imdbesmodcopy.sample(frac=1)\n",
    "imdbesmodcopy_train = imdbesmodcopy.iloc[2500:]\n",
    "imdbesmodcopy_test = imdbesmodcopy.iloc[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(imdbesmodcopy_train['review_es_mod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length: 1870\n"
     ]
    }
   ],
   "source": [
    "# cambiando el texto a secuencias\n",
    "X_train = tokenizer.texts_to_sequences(imdbesmodcopy_train['review_es_mod'])\n",
    "X_test = tokenizer.texts_to_sequences(imdbesmodcopy_test['review_es_mod'])\n",
    "\n",
    "# pad sequences\n",
    "maxlen = max([len(x) for x in X_train])\n",
    "\n",
    "print('Max Length:', maxlen)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = imdbesmodcopy_train['sentiemiento_token'].values\n",
    "y_test = imdbesmodcopy_test['sentiemiento_token'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(max_features, embed_size),\n",
    "    LSTM(60, return_sequences=True),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenando el modelo\n",
    "batch_size = 100\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validacion y evaluacion\n",
    "validation_split = 0.5\n",
    "validation_size  =int(len(X_test) * validation_split)\n",
    "\n",
    "X_val = X_test[:validation_size]\n",
    "y_val = y_test[:validation_size]\n",
    "\n",
    "X_eval = X_test[validation_size:]\n",
    "y_eval = y_test[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float8_e3m4'\n",
      "Epoch 1/3\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2405s\u001b[0m 5s/step - accuracy: 0.7631 - loss: 0.4715 - val_accuracy: 0.5120 - val_loss: 1.4819\n",
      "Epoch 2/3\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2426s\u001b[0m 5s/step - accuracy: 0.9155 - loss: 0.2186 - val_accuracy: 0.5152 - val_loss: 1.7649\n",
      "Epoch 3/3\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2526s\u001b[0m 5s/step - accuracy: 0.9461 - loss: 0.1478 - val_accuracy: 0.5080 - val_loss: 1.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ffc49a26d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 595ms/step - accuracy: 0.8854 - loss: 0.3002\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_eval, y_eval, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3097416162490845 - Test accuracy: 0.881600022315979\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {score[0]} - Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas del modelo\n",
    "\n",
    "Modelo piloto. Este se modificará luego de hacer pruebas de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = [\n",
    "    \"El café en este lugar es increíblemente aromático y el ambiente es perfecto para relajarse. ¡Muy recomendado!\",\n",
    "    \"El servicio fue lento y las porciones pequeñas para el precio. No lo recomendaría.\",\n",
    "    \"El libro tiene una trama cautivadora y personajes memorables. Me mantuvo enganchado de principio a fin.\",\n",
    "    \"La película fue predecible y los efectos especiales parecían anticuados. Me decepcionó.\",\n",
    "    \"Este champú dejó mi cabello suave y brillante, y el aroma es maravilloso. Definitivamente lo volveré a comprar.\",\n",
    "    \"La aplicación se traba constantemente y consume mucha batería. No vale la pena descargarla.\",\n",
    "    \"La chaqueta es súper cómoda y tiene un diseño moderno. Perfecta para el invierno.\",\n",
    "    \"La comida llegó fría y con un sabor mediocre. No volveré a pedir de aquí.\",\n",
    "    \"El curso es muy claro y los ejemplos son prácticos. Aprendí muchísimo en poco tiempo.\",\n",
    "    \"Las instrucciones no eran claras y el producto vino defectuoso. Un desperdicio de dinero.\"\n",
    "]\n",
    "sentimiento = [\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo',\n",
    "    'positivo',\n",
    "    'negativo'\n",
    "]\n",
    "resenias = pd.DataFrame({'review_es': prueba, 'sentimiento': sentimiento})\n",
    "resenias = resenias.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipe(df : pd.DataFrame, col_in : str, col_out : str) -> pd.DataFrame:\n",
    "    result = (df\n",
    "              .pipe(eliminar_etiquetas_html, col_in, col_out)\n",
    "              .pipe(caracteres_especiales, col_out, col_out)\n",
    "              .pipe(espacios_extra, col_out, col_out)\n",
    "              .pipe(remove_stop_words, col_out, col_out)\n",
    "              .pipe(lemmatizador, col_out, col_out))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenias_treated = preprocessing_pipe(resenias, 'review_es', 'review_es_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenias_treated['sentimiento_token'] = resenias_treated['sentimiento'].map({'positivo': 1, 'negativo': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>review_es_mod</th>\n",
       "      <th>sentimiento_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El curso es muy claro y los ejemplos son práct...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>curso claro ejemplo práctico Aprendí muchísimo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Las instrucciones no eran claras y el producto...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>instrucción claro producto venir defectuoso de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El servicio fue lento y las porciones pequeñas...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>servicio lento porción pequeño precio recomendar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La chaqueta es súper cómoda y tiene un diseño ...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>chaqueta súper cómodo diseño moderno Perfecta ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La película fue predecible y los efectos espec...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>película predecible efecto especial parecer an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La comida llegó fría y con un sabor mediocre. ...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>comida llegar fría sabor mediocre volver pedir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El café en este lugar es increíblemente aromát...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>café lugar increíblemente aromático ambiente p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La aplicación se traba constantemente y consum...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>aplicación trar constantemente consumir mucho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El libro tiene una trama cautivadora y persona...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>libro trama cautivadora personaje memorable ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este champú dejó mi cabello suave y brillante,...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>champú dejar cabello suave brillante aroma mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_es sentimiento  \\\n",
       "8  El curso es muy claro y los ejemplos son práct...    positivo   \n",
       "9  Las instrucciones no eran claras y el producto...    negativo   \n",
       "1  El servicio fue lento y las porciones pequeñas...    negativo   \n",
       "6  La chaqueta es súper cómoda y tiene un diseño ...    positivo   \n",
       "3  La película fue predecible y los efectos espec...    negativo   \n",
       "7  La comida llegó fría y con un sabor mediocre. ...    negativo   \n",
       "0  El café en este lugar es increíblemente aromát...    positivo   \n",
       "5  La aplicación se traba constantemente y consum...    negativo   \n",
       "2  El libro tiene una trama cautivadora y persona...    positivo   \n",
       "4  Este champú dejó mi cabello suave y brillante,...    positivo   \n",
       "\n",
       "                                       review_es_mod  sentimiento_token  \n",
       "8  curso claro ejemplo práctico Aprendí muchísimo...                  1  \n",
       "9  instrucción claro producto venir defectuoso de...                  0  \n",
       "1   servicio lento porción pequeño precio recomendar                  0  \n",
       "6  chaqueta súper cómodo diseño moderno Perfecta ...                  1  \n",
       "3  película predecible efecto especial parecer an...                  0  \n",
       "7  comida llegar fría sabor mediocre volver pedir...                  0  \n",
       "0  café lugar increíblemente aromático ambiente p...                  1  \n",
       "5  aplicación trar constantemente consumir mucho ...                  0  \n",
       "2  libro trama cautivadora personaje memorable ma...                  1  \n",
       "4  champú dejar cabello suave brillante aroma mar...                  1  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resenias_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_text_plain = resenias_treated['review_es_mod'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertTokenizer' object has no attribute 'texts_to_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prueba_text_plain_token \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts_to_sequences\u001b[49m(prueba_text_plain[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_es_mod\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m prueba_text_plain_token \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mpad_sequences(prueba_text_plain_token, maxlen\u001b[38;5;241m=\u001b[39mmaxlen, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertTokenizer' object has no attribute 'texts_to_sequences'"
     ]
    }
   ],
   "source": [
    "prueba_text_plain_token = tokenizer.texts_to_sequences(prueba_text_plain['review_es_mod'])\n",
    "prueba_text_plain_token = sequence.pad_sequences(prueba_text_plain_token, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
